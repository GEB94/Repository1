import math
import random 

class Neurona:
    def __init__(self, n_inputs):
        self.n_inputs = n_inputs
        self.inputs = [1 for _ in range(n_inputs)]
        self.weights = [random.random() for _ in range(n_inputs)]
        self.b = 1

    def sigmoid(self, inputs, weights):
        x = sum(inputs[i] * weights[i] for i in range(self.n_inputs))
        x = x + self.b
        return 1 / (1 + math.exp(-x))

class NeuronalNetwork:
    def __init__(self):
        self.input_layer = [Neurona(2) for _ in range(2)]
        self.hidden_layer = [Neurona(2) for _ in range(3)]
        self.output_layer = [Neurona(3) for _ in range(2)]
        self.learning_rate = 0.25

    def forward_propagation(self, inputs):
        hidden_outputs = [neuron.sigmoid(inputs, neuron.weights) for neuron in self.hidden_layer]
        self.outputs = [neuron.sigmoid(hidden_outputs, neuron.weights) for neuron in self.output_layer]
        return self.outputs

    def backward_propagation(self, inputs, targets):
        outputs = self.forward_propagation(inputs)
        while outputs != targets:
            deltas_output_layer = [outputs[i] - targets[i] for i in range(2)]
            deltas_hidden_layer = [sum(neuron.weights[j] * deltas_output_layer[j] for j in range(2)) for neuron in self.hidden_layer]

            for i, neuron in enumerate(self.output_layer):
                for j in range(2):
                    delta_w = deltas_output_layer[j] * self.learning_rate * neuron.inputs[j]
                    delta_b = deltas_output_layer[j] * self.learning_rate
                  neuron.weights[j] = neuron.weights[j] - delta_w
                    neuron.b = neuron.b - delta_b

            for i, neuron in enumerate(self.hidden_layer):
                for j in range(2):
                    delta_w = deltas_hidden_layer[i] * self.learning_rate * neuron.inputs[j]
                    delta_b = deltas_hidden_layer[i] * self.learning_rate
                    neuron.weights[j] = neuron.weights[j] - delta_w
                    neuron.b = neuron.b - delta_b

            outputs = self.forward_propagation(inputs)

nn = NeuronalNetwork()
inputs = [0, 1]
targets = [0, 1]  
while nn.forward_propagation(inputs) != targets:
    nn.backward_propagation(inputs, targets)
    hidden_layer_results = [neuron.sigmoid(inputs, neuron.weights) for neuron in nn.hidden_layer]
    output_layer_results = nn.forward_propagation(inputs)

print("Hidden layer results:", hidden_layer_results)
print("Output layer results:", output_layer_results)
